#cloud-config
fqdn: ${fqdn}
hostname: ${name}
manage_etc_hosts: true
prefer_fqdn_over_hostname: true
preserve_hostname: false
package_upgrade: true
package_update: true

packages:
  - bind-utils
  - curl
  - unzip
  - python3-pip

runcmd:
  - dnf config-manager --add-repo https://rpm.releases.hashicorp.com/AmazonLinux/hashicorp.repo
  - dnf -y install consul
  - systemctl enable consul && systemctl start consul
  - dnf -y install https://repo.percona.com/yum/percona-release-latest.noarch.rpm
  - percona-release setup -y pmm3-client
  - dnf -y install pmm-client
  - curl -s ${scripts_path}/waiter.sh -o /usr/local/bin/waiter.sh
  - chmod 0755 /usr/local/bin/waiter.sh
  - bash /usr/local/bin/waiter.sh readyz ${name} ${fqdn} ${environment_name}
  - pmm-admin config --az="us-east-1f" --region="us-east-1" --metrics-mode=push --force --server-insecure-tls --server-url='https://admin:${pmm_admin_password}@${pmm_server_endpoint}' ${fqdn} generic ${name}
  - dnf -y install https://github.com/ncabatoff/process-exporter/releases/download/v0.8.5/process-exporter_0.8.5_linux_amd64.rpm
  - bash /usr/local/bin/waiter.sh process-exporter ${name} ${fqdn} ${environment_name}
  - pmm-admin add external --group=processes --listen-port=9256 --environment="prod" --service-name="${name}-processes" --cluster="processes-cluster"
  - percona-release setup -y psmdb-60
  - PERCONA_TELEMETRY_DISABLE=1 dnf -y install percona-mongodb-mongosh git maven
  - git clone https://github.com/johnlpage/POCDriver /root/POCDriver
  - cd /root/POCDriver && mvn clean package
  - /bin/bash /usr/local/bin/wait_all_shards.sh
  - systemctl enable pocdriver && systemctl start pocdriver

write_files:
  - path: /etc/resolv.conf
    permissions: "0644"
    content: |
      ; generated by #cloud-config
      search ${local_domain} ec2.internal
      options timeout:2 attempts:5
      nameserver 10.0.0.2

  - path: /etc/consul.d/consul.hcl
    permissions: "0644"
    content: |
      bind_addr = "0.0.0.0"
      client_addr = "0.0.0.0"
      data_dir = "/opt/consul"
      enable_local_script_checks = true
      node_name="${name}"
      retry_join = ["pmm-server", "sysbench", "bastion"]
      server = false
      ui_config{
        enabled = true
      }

  - path: /etc/consul.d/process-exporter-check-http.json
    permissions: "0644"
    content: |
      {
        "service": {
          "address": "${fqdn}",
          "name": "process-exporter",
          "port": 9256,
          "tags": ["${name}"],
          "checks": [{
            "http": "http://${fqdn}:9256/metrics",
            "interval": "3s",
            "success_before_passing": 3,
            "timeout": "5s"
          }]
        }
      }

  - path: /usr/local/bin/waiter.sh
    permissions: "0755"
    content: |
      #!/bin/bash
      # Script to do all the waiting
      # File contents will be downloaded from githubcontent.com

  - path: /root/init_shards.js
    content: |
      sh.enableSharding('ycsb');
      var y = db.getSiblingDB('ycsb')
      y.getCollectionNames().forEach(function (n) { if (n == 'system.profile') {} else { print("Dropping "+n); y.getCollection(n).drop();} });
      for (i=0; i<10; i++) {
        var col="ycsb.pocdriver"+i;
        print("Enable sharding for "+col)
        sh.shardCollection(col, {"_id.w": 1, "_id.i": "hashed"});
        print("Creating shard range 0-1/2-3 for "+col)
        db.adminCommand({ moveRange: col, min: { '_id.w': 2, '_id.i': MinKey }, max: { '_id.w': MaxKey, '_id.i': MaxKey }, toShard: 'shard-1' });
      }

  - path: /usr/local/bin/wait_all_shards.sh
    permissions: "0755"
    content: |
      #!/bin/bash

      # Wait for mongos
      echo "-- Waiting for all 9 mongo servers..."

      for (( i=1 ; i<=100 ; i++ )); do
        shardCount=0
        primaryCount=0
        for j in cfg rs-shard-0 rs-shard-1; do
          cnt=$(dig +short @127.0.0.1 -p 8600 mongo-60-$${j}.service.consul SRV | wc -l)
          echo "mongo-60-$${j} has $${cnt}/3 members online"
          if [[ $cnt -eq 3 ]]; then
            ((shardCount++))
          fi
          prim=$(dig +short @127.0.0.1 -p 8600 mongo-60-$${j}-primary.service.consul SRV | wc -l)
          echo "mongo-60-$${j} has $${prim} primary member"
          if [[ $prim -eq 1 ]]; then
            ((primaryCount++))
          fi
        done
        if [[ $shardCount -eq 3 ]] && [[ $primaryCount -eq 3 ]]; then
          echo "-- Looks like all 3 mongo shards are online with primary"
          sleep 2
          break
        fi
        echo "-- Only $${shardCount} mongo shards online; retry $${i}/100"
        sleep 2
      done

  - path: /usr/local/bin/exec_pocdriver.sh
    permissions: "0744"
    content: |
      #!/bin/bash

      function runner() {
        local name=$1
        local ins=$2
        local ups=$3
        local rng=$4
        local key=$5
        for i in rs-0-0 rs-0-1 rs-0-2 rs-1-0 rs-1-1 rs-1-2; do
          pmm-admin annotate --service-name=mongo-60-$${i} "${name}"
        done
        /bin/java -jar /root/POCDriver/bin/POCDriver.jar \
          -c mongodb://ycsb:${mongodb_ycsb_password}@mongo-60-mongos-0:27019 \
          --duration 3600 \
          --namespace ycsb.pocdriver \
          --nosharding \
          --arrays 6:12 \
          --inserts $ins --updates $ups --rangequeries $rng --keyqueries $key \
          --projectfields 1 --collections 10
        sleep 20s
      }
      while true; do
        # drop all collections; reset
        mongosh mongodb://ycsb:${mongodb_ycsb_password}@mongo-60-mongos-0:27019/ycsb --authenticationDatabase admin /root/init_shards.js
        runner "insert_only" 1000 0 0 0
        runner "update_only" 0 1000 0 0
        runner "read_only" 0 0 100 100
      done

  - path: /usr/lib/systemd/system/pocdriver.service
    content: |
      [Unit]
      Description=POCDriver - MongoDB Benchmark
      After=network.target

      [Service]
      Type=simple
      Restart=on-failure
      RestartSec=10
      ExecStart=/usr/local/bin/exec_pocdriver.sh

      [Install]
      WantedBy=multi-user.target
