#cloud-config
fqdn: ${fqdn}
hostname: ${name}
manage_etc_hosts: true
prefer_fqdn_over_hostname: true
preserve_hostname: false
package_upgrade: true
package_update: true

packages:
  - bind-utils
  - curl
  - docker

runcmd:
  - dnf config-manager --add-repo https://rpm.releases.hashicorp.com/AmazonLinux/hashicorp.repo
  - dnf -y install consul
  - systemctl enable consul
  - bash /root/consul-advertise-addr.sh
  - systemctl start consul
  - sed -i 's/enforcing/permissive/g' /etc/selinux/config && /sbin/setenforce 0
  - dnf -y install https://repo.percona.com/yum/percona-release-latest.noarch.rpm
  - percona-release setup -y ps-80
  - PERCONA_TELEMETRY_DISABLE=1 dnf -y install percona-server-client
  - percona-release setup -y pmm3-client
  - dnf -y install pmm-client
  - curl -s ${scripts_path}/waiter.sh -o /usr/local/bin/waiter.sh
  - chmod 0755 /usr/local/bin/waiter.sh
  - bash /usr/local/bin/waiter.sh readyz ${name} ${fqdn} ${environment_name}
  - pmm-admin config --az="us-east-1f" --region="us-east-1" --metrics-mode=push --force --server-insecure-tls --server-url='https://admin:${pmm_admin_password}@${pmm_server_endpoint}' ${fqdn} generic ${name}
  - docker run --net host --restart=unless-stopped -d --name haproxy -v /etc/haproxy:/usr/local/etc/haproxy:ro docker.io/library/haproxy:latest
  - bash /usr/local/bin/waiter.sh haproxy-exporter ${name} ${fqdn} ${environment_name}
  - pmm-admin add haproxy --listen-port=8404 --metrics-path=/metrics --environment="prod" --cluster="haproxy" --replication-set="haproxy"
  - dnf -y install https://github.com/ncabatoff/process-exporter/releases/download/v0.8.5/process-exporter_0.8.5_linux_amd64.rpm
  - bash /usr/local/bin/waiter.sh process-exporter ${name} ${fqdn} ${environment_name}
  - pmm-admin add external --group=processes --listen-port=9256 --environment="prod" --service-name="${name}-processes" --cluster="processes-cluster"

write_files:
  - path: /etc/resolv.conf
    permissions: "0644"
    content: |
      ; generated by #cloud-config
      search ${local_domain} ec2.internal
      options timeout:2 attempts:5
      nameserver 10.0.0.2

  - path: /etc/consul.d/consul.hcl
    permissions: "0644"
    content: |
      bind_addr = "0.0.0.0"
      client_addr = "0.0.0.0"
      data_dir = "/opt/consul"
      enable_local_script_checks = true
      node_name="${name}"
      retry_join = ["pmm-server", "sysbench", "bastion"]
      server = false
      ui_config{
        enabled = true
      }

  - path: /root/consul-advertise-addr.sh
    permissions: "0700"
    content: |
      #!/bin/bash
      my_private_ip=$(ip a sh eth0 | awk '/inet / {print $2}' | awk -F '/' '{print $1}')
      echo "advertise_addr = \"$my_private_ip\"" >> /etc/consul.d/consul.hcl

  - path: /etc/consul.d/haproxy-exporter-check-http.json
    permissions: "0644"
    content: |
      {
        "service": {
          "address": "${fqdn}",
          "name": "haproxy-exporter",
          "port": 8404,
          "tags": ["${name}"],
          "checks": [{
            "http": "http://${fqdn}:8404/metrics",
            "interval": "3s",
            "success_before_passing": 3,
            "timeout": "5s"
          }]
        }
      }

  - path: /etc/consul.d/process-exporter-check-http.json
    permissions: "0644"
    content: |
      {
        "service": {
          "address": "${fqdn}",
          "name": "process-exporter",
          "port": 9256,
          "tags": ["${name}"],
          "checks": [{
            "http": "http://${fqdn}:9256/metrics",
            "interval": "3s",
            "success_before_passing": 3,
            "timeout": "5s"
          }]
        }
      }

  - path: /usr/local/bin/mysql-check.sh
    permissions: "0755"
    content: |
      #!/bin/bash
      VIP_PORT=$2
      MYSQL_HOST=$3
      MYSQL_PORT=$4
      if [[ $VIP_PORT -eq 3306 ]]; then
        # Testing Percona XtraDB Cluster
        mysqlquery="/bin/mysql -h $MYSQL_HOST -P $MYSQL_PORT -u sysbench-haproxy-pxc -p${pxc_80_password} -BNe"
        size=$(2>/dev/null $mysqlquery "SHOW GLOBAL STATUS LIKE 'wsrep_cluster_size'" | /bin/cut -f2)
        if [[ -z "$${size}" ]]; then let size=0; fi
        echo "$${MYSQL_HOST} (PXC) has $${size}/3 members."
      elif [[ $VIP_PORT -eq 33061 ]]; then
        # Testing Percona Server 8.4 Group Replication
        mysqlquery="/bin/mysql -h $MYSQL_HOST -P $MYSQL_PORT -u sysbench-haproxy-percona-gr -p${ps_84_gr_password} -BNe"
        size=$(2>/dev/null $mysqlquery "SELECT COUNT(*) FROM performance_schema.replication_group_members WHERE MEMBER_STATE=\"ONLINE\"")
        if [[ -z "$${size}" ]]; then let size=0; fi
        echo "$${MYSQL_HOST} (GR) has $${size}/3 members."
      fi
      if [[ $size -eq 3 ]]; then exit 0; fi
      # Anything else, consider this backend down
      exit 1

  - path: /usr/local/bin/waiter.sh
    permissions: "0755"
    content: |
      #!/bin/bash
      # Script to do all the waiting
      # File contents will be downloaded from githubcontent.com

  - path: /etc/haproxy/haproxy.cfg
    content: |
      global
        daemon
        log stdout format raw local0 notice
        maxconn 4096
        stats socket /var/lib/haproxy/stats
        external-check
        insecure-fork-wanted

      defaults
        log     global
        maxconn 2000
        mode    http
        option  dontlognull
        option  tcplog
        retries 3
        timeout client      50000
        timeout connect      5000
        timeout server      50000

      resolvers mynameservers
        parse-resolv-conf

      listen percona-xtradb-cluster
        balance roundrobin
        bind 0.0.0.0:3306
        mode tcp
        option external-check
        external-check command /usr/local/bin/mysql-check.sh
        default-server inter 2s downinter 5s rise 3 fall 3
        server percona-xtradb-cluster-0 percona-xtradb-cluster-0:3306 check
        server percona-xtradb-cluster-1 percona-xtradb-cluster-1:3306 check
        server percona-xtradb-cluster-2 percona-xtradb-cluster-2:3306 check

      listen percona-gr-cluster
        balance roundrobin
        bind 0.0.0.0:33061
        mode tcp
        option external-check
        external-check command /usr/local/bin/mysql-check.sh
        default-server inter 2s downinter 5s rise 3 fall 3
        server percona-server-84-gr-1 percona-server-84-gr-1:3306 check
        server percona-server-84-gr-2 percona-server-84-gr-2:3306 check
        server percona-server-84-gr-3 percona-server-84-gr-3:3306 check

      frontend stats
        bind *:8404
        http-request use-service prometheus-exporter if { path /metrics }
        stats enable
        stats refresh 10s
        stats uri /stats
