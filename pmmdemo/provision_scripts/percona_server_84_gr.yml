#cloud-config
fqdn: ${fqdn}
hostname: ${name}
manage_etc_hosts: true
prefer_fqdn_over_hostname: true
preserve_hostname: false
package_upgrade: true
package_update: true

packages:
  - bind-utils
  - curl

bootcmd:
  - while [[ ! -b $(readlink -f /dev/nvme1n1) ]]; do echo "waiting for the disk..."; sleep 5; done
  - mkfs.xfs -L data /dev/nvme1n1
  - mkdir -p /data

mounts:
  - ["/dev/nvme1n1", "/data", "xfs", "defaults,noatime", "0", "2"]

runcmd:
  - dnf config-manager --add-repo https://rpm.releases.hashicorp.com/AmazonLinux/hashicorp.repo
  - dnf -y install consul
  - systemctl enable consul && systemctl start consul
  - dnf -y install https://repo.percona.com/yum/percona-release-latest.noarch.rpm
  - percona-release setup -y ps-84-lts
  - PERCONA_TELEMETRY_DISABLE=1 dnf -y install percona-server-server
  - percona-release setup -y pmm3-client
  - dnf -y install pmm-client
  - echo '!includedir /etc/my.cnf.d/' >> /etc/my.cnf
  - chown mysql:mysql /data/
  - semanage fcontext -a -t mysqld_db_t "/data(/.*)?" && restorecon -Rv /data
  - semanage port -a -t mysqld_port_t -p tcp 33061
  - systemctl enable mysqld.service
  - systemctl start mysqld.service
  - systemctl status mysqld.service
  - bash /root/init-mysql.sh
  - bash /usr/local/bin/waiter.sh readyz
  - pmm-admin config --az="us-east-1f" --region="us-east-1" --metrics-mode=push --force --server-insecure-tls --server-url='https://admin:${pmm_password}@${pmm_server_endpoint}' ${fqdn} generic ${name}
  - bash /usr/local/bin/waiter.sh mysql
  - pmm-admin add mysql --metrics-mode=push --username=pmm-admin --password='${mysql_root_password}' --cluster='percona-server-84-gr' --replication-set='percona-server-84-gr' --environment='prod' --query-source=slowlog --service-name="${name}-mysql"
  - dnf -y install https://github.com/ncabatoff/process-exporter/releases/download/v0.8.5/process-exporter_0.8.5_linux_amd64.rpm
  - bash /usr/local/bin/waiter.sh process-exporter
  - pmm-admin add external --group=processes --listen-port=9256 --environment="prod" --service-name="${name}-processes" --cluster="processes-cluster"

write_files:
  - path: /etc/resolv.conf
    permissions: "0644"
    content: |
      ; generated by #cloud-config
      search ${local_domain} ec2.internal
      options timeout:2 attempts:5
      nameserver 10.0.0.2
  - path: /etc/consul.d/consul.hcl
    permissions: "0644"
    content: |
      bind_addr = "0.0.0.0"
      client_addr = "0.0.0.0"
      data_dir = "/opt/consul"
      enable_local_script_checks = true
      node_name="${name}"
      retry_join = ["pmm-server", "sysbench", "bastion"]
      server = false
      ui_config{
        enabled = true
      }

  - path: /usr/local/bin/consul-check-mysql.sh
    permissions: "0755"
    content: |
      #!/bin/bash
      # Set MySQL server credentials
      MYSQL_USER="consul-health-check"
      MYSQL_PASSWORD="${mysql_root_password}"
      if [[ "$$1" == "primary" ]]; then
        res=$(mysql --user="$MYSQL_USER" --password="$MYSQL_PASSWORD" -BNe "SELECT MEMBER_HOST FROM performance_schema.replication_group_members WHERE MEMBER_ROLE=\"PRIMARY\"")
        if [[ "$${res}" =~ "${name}" ]]; then
          echo "we are primary"
          exit 0
        else
          exit 1
        fi
      else
        while true ; do
          # Attempt to connect using MySQL Shell with a 2-second timeout
          mysql --user="$MYSQL_USER" --password="$MYSQL_PASSWORD" --connect-timeout=2 -e "SELECT 1"
          # Check the exit status of mysqlsh to determine connection success
          if [[ $? -eq 0 ]]; then
            echo "Successfully connected to MySQL service."
            exit 0
          else
            echo -n "Connection attempt to MySQL service failed. Sleeping 1 second... "
            date
            sleep 1
          fi
        done
      fi
  - path: /etc/consul.d/percona-server-84-gr-service.json
    permissions: "0644"
    content: |
      {
        "services": [{
          "address": "${fqdn}",
          "name": "percona-server-84-gr",
          "port": 3306,
          "tags": ["${name}"],
          "checks": [{
            "interval": "2s",
            "success_before_passing": 3,
            "timeout": "2s",
            "args": [ "bash", "/usr/local/bin/consul-check-mysql.sh" ]
          }]
        },
        {
          "address": "${fqdn}",
          "name": "percona-server-84-gr-primary",
          "tags": ["${name}"],
          "checks": [{
            "interval": "2s",
            "success_before_passing": 3,
            "timeout": "2s",
            "args": [ "bash", "/usr/local/bin/consul-check-mysql.sh", "primary" ]
          }]
        }]
      }
  - path: /etc/consul.d/process-exporter-check-http.json
    permissions: "0644"
    content: |
      {
        "service": {
          "address": "${fqdn}",
          "id": "process-exporter",
          "name": "process-exporter",
          "port": 9256,
          "tags": ["${name}"],
          "checks": [
            {
            "HTTP": "http://${fqdn}:9256/metrics",
            "ID": "process-exporter_check_http",
            "Interval": "3s",
            "Method": "GET",
            "Name": "Check for process-exporter using HTTP",
            "Notes": "Check for process-exporter using HTTP. Monitoring of per-process metrics are enabled with this service.",
            "ServiceID": "process-exporter_check_http",
            "Success_before_passing": 3,
            "Timeout": "5s"
            }
          ]
        }
      }
  - path: /usr/local/bin/waiter.sh
    permissions: "0755"
    content: |
      #!/bin/bash
      # Script to do all the waiting
      service="$1"
      if [[ $service == "process-exporter" ]]; then
        # process-exporter
        while true; do
          # Get the status of the process-exporter_check_http check
          status=$(dig @127.0.0.1 -p 8600 ${name}.process-exporter.service.consul SRV | awk '/SRV.*${fqdn}\.$/ {print $1}')
          if [[ $status == "${name}.process-exporter.service.consul." ]]; then
            echo "process-exporter check is passing."
            exit 0
          fi

          # If the check is not passing, wait for a short interval and try again
          echo "process-exporter check is not passing. Will retry in 3 seconds..."
          sleep 3
        done
      elif [[ $service == "mysql" ]]; then
        # mysql
        while true; do
          # Get the status of the mysql_check_http check
          status=$(dig @127.0.0.1 -p 8600 ${name}.percona-server-84-gr.service.consul SRV | awk '/SRV.*${fqdn}\.$/ {print $1}')
          if [[ $status == "${name}.percona-server-84-gr.service.consul." ]]; then
            echo "mysql check is passing."
            exit 0
          fi

          # If the check is not passing, wait for a short interval and try again
          echo "mysql check is not passing. Will retry in 3 seconds..."
          sleep 3
        done
      elif [[ $service == "gr-primary" ]]; then
        # group replication primary
        while true; do
          status=$(dig +short @127.0.0.1 -p 8600 percona-server-84-gr-primary.service.consul SRV)
          if [[ $status =~ "${environment_name}.local" ]]; then
            echo "gr-primary check is passing"
            exit 0
          else
            echo "gr-primary check is not passing"
          fi
          sleep 1
        done
      elif [[ $service == "readyz" ]] ; then
        # PMM readyz
        while true; do
          # Check for DNS :facepalm:
          dnsstatus=$(dig pmm-server.${environment_name}.local A | awk '/A.*10.*$/ {print $1}')

          if [[ $dnsstatus == "pmm-server.${environment_name}.local." ]]; then
            echo "PMMreadyz_check_http DNS check is passing."

            # Get the status of the PMMreadyz_check_http check
            status=$(dig @127.0.0.1 -p 8600 pmmreadyz.service.consul SRV | awk '/SRV.*bastion.${environment_name}.local.$/ {print $1}')
        
            if [[ $status == "pmmreadyz.service.consul." ]]; then
              echo "PMMreadyz_check_http check is passing."
              exit 0  
            fi
          else
            echo "PMMreadyz_check_http DNS check is not passing."
          fi
          # If the check is not passing, wait for a short interval and try again
          echo "PMMreadyz_check_http check is not passing. Will retry in 1 second..."
          sleep 1
        done
      fi
  - path: /root/.my.cnf
    permissions: "0600"
    content: |
      [client]
      user=root
      password="${mysql_root_password}"

  - path: /etc/my.cnf
    content: |
      [mysqld]

      # Host specific replication configuration
      #
      report_host = ${fqdn}
      report_port = 3306
      server_id   = ${index}

      # Generic
      #
      datadir=/data
      socket=/var/lib/mysql/mysql.sock
      log-error=/var/log/mysqld.log
      pid-file=/var/run/mysqld/mysqld.pid
      log_error_verbosity=3
      log_error_suppression_list='MY-013360'
      loose-validate_password.policy=0
      percona_telemetry_disable=1

      # Config binary logs
      #
      log-bin
      binlog_format=ROW
      binlog_expire_logs_seconds=86400
      binlog_space_limit=10G

      # Configure slow logs
      #
      slow_query_log=ON
      slow_query_log_always_write_time=1
      slow_query_log_use_global_control=all
      log_slow_rate_limit=2       # Log every other slow query
      log_slow_rate_type='query'
      log_slow_admin_statements=ON
      log_slow_replica_statements=ON
      log_slow_verbosity=full
      long_query_time=0

      # InnoDB
      #
      innodb_buffer_pool_size=1G
      innodb_flush_method=O_DIRECT

      # Configure statistics
      #
      userstat=ON
      performance_schema=ON
      innodb_monitor_enable=module_index
      
      # Group Replication
      #
      disabled_storage_engines="MyISAM,BLACKHOLE,FEDERATED,ARCHIVE,MEMORY"
      gtid_mode = ON
      enforce_gtid_consistency = ON
      plugin_load_add='group_replication.so'
      loose-group_replication_bootstrap_group=off
      loose-group_replication_group_name="${percona_group_replication_uuid}"
      loose-group_replication_group_seeds="percona-server-84-gr-1:33061,percona-server-84-gr-2:33061,percona-server-84-gr-3:33061"
      loose-group_replication_local_address="${name}:33061"
      loose-group_replication_recovery_get_public_key=ON 
      loose-group_replication_paxos_single_leader=ON
      loose-group_replication_single_primary_mode=ON
      loose-group_replication_start_on_boot=off
 
      !includedir /etc/my.cnf.d/

  - path: /root/init-mysql.sh
    content: |
      #!/bin/bash
      mysqlquery="mysql --defaults-file=/root/.my.cnf -Bse"
      nologbin="SET SQL_LOG_BIN=0;"
      # This need not be run on the replicas because replication will propagate them everywhere
      provision_users() {
        INITIAL_ROOT_PASSWORD=$(grep "root@localhost:" /var/log/mysqld.log | tail -n1 | rev | cut -d' ' -f1 | rev)
        if [ -n "$INITIAL_ROOT_PASSWORD" ]; then
          mysql --connect-expired-password -uroot -p$INITIAL_ROOT_PASSWORD -Bse "ALTER USER root@localhost IDENTIFIED BY '${mysql_root_password}';"
          if [ $? -ne 0 ]; then
            echo "Error: Failed to change root password"
          fi
          echo "Password for root@localhost successfully changed"
        else
          echo "Error: Initial root password not found in /data/mysqld.log"
        fi      
        $mysqlquery "$nologbin CREATE USER 'pmm-admin'@'localhost' IDENTIFIED BY '${mysql_root_password}' WITH MAX_USER_CONNECTIONS 100;";
        $mysqlquery "$nologbin GRANT SELECT, PROCESS, REPLICATION CLIENT, RELOAD, BACKUP_ADMIN ON *.* TO 'pmm-admin'@'localhost';";
        $mysqlquery "$nologbin CREATE USER 'consul-health-check'@'localhost' IDENTIFIED BY '${mysql_root_password}' WITH MAX_USER_CONNECTIONS 2;";
        $mysqlquery "$nologbin GRANT USAGE ON *.* TO 'consul-health-check'@'localhost';";
        $mysqlquery "$nologbin GRANT SELECT ON performance_schema.replication_group_members TO 'consul-health-check'@'localhost';";
        $mysqlquery "$nologbin CREATE USER replica@'%' IDENTIFIED BY '${mysql_replica_password}';";
        $mysqlquery "$nologbin GRANT REPLICATION SLAVE, CONNECTION_ADMIN, BACKUP_ADMIN, GROUP_REPLICATION_STREAM, REPLICATION CLIENT ON *.* TO replica@'%';";
        $mysqlquery "$nologbin CREATE USER replica@'localhost' IDENTIFIED BY '${mysql_replica_password}';";
        $mysqlquery "$nologbin GRANT REPLICATION SLAVE, CONNECTION_ADMIN, BACKUP_ADMIN, GROUP_REPLICATION_STREAM, REPLICATION CLIENT ON *.* TO replica@'localhost';";
        $mysqlquery "$nologbin CREATE USER proxysql@'%' IDENTIFIED BY '${proxysql_monitor_password}';";
        $mysqlquery "$nologbin GRANT ALL PRIVILEGES ON *.* TO proxysql@'%';";
        $mysqlquery "$nologbin CREATE USER 'sysbench-direct-percona-gr'@'%' IDENTIFIED BY '${mysql_sysbench_password}';";
        $mysqlquery "$nologbin GRANT ALL PRIVILEGES ON sbtest_direct_gr.* TO 'sysbench-direct-percona-gr'@'%';";
        $mysqlquery "$nologbin CREATE USER 'sysbench-proxysql-percona-gr'@'%' IDENTIFIED BY '${mysql_sysbench_password}';";
        $mysqlquery "$nologbin GRANT ALL PRIVILEGES ON sbtest_proxysql_gr.* TO 'sysbench-proxysql-percona-gr'@'%';";
        $mysqlquery "$nologbin CREATE USER 'sysbench-haproxy-percona-gr'@'%' IDENTIFIED BY '${mysql_sysbench_password}';";
        $mysqlquery "$nologbin GRANT ALL PRIVILEGES ON sbtest_haproxy_gr.* TO 'sysbench-haproxy-percona-gr'@'%';";
      }

      provision_tables() {
        $mysqlquery "CREATE DATABASE IF NOT EXISTS sbtest_direct_gr;"
        $mysqlquery "CREATE DATABASE IF NOT EXISTS sbtest_proxysql_gr;"
        $mysqlquery "CREATE DATABASE IF NOT EXISTS sbtest_haproxy_gr;"
      }

      if [[ "${name}" == "percona-server-84-gr-1" ]]; then
          # Start GR on primary node
          # If we are running on the primary node (i.e., index == 1), start the GR instance in bootstrap mode.
          provision_users
          provision_tables
          # Configure DR channel
          mysql --defaults-file=/root/.my.cnf -Bse "SET SQL_LOG_BIN=0;CHANGE REPLICATION SOURCE TO SOURCE_USER='replica', SOURCE_PASSWORD='${mysql_replica_password}' FOR CHANNEL 'group_replication_recovery';"
          # Start GR in bootstrap mode
          mysql --defaults-file=/root/.my.cnf -Bse "SET GLOBAL group_replication_bootstrap_group=ON;START GROUP_REPLICATION;SET GLOBAL group_replication_bootstrap_group=OFF;"
      else
          # Start GR on secondary nodes; wait for PRIMARY
          /usr/local/bin/waiter.sh gr-primary
          provision_users
          mysql --defaults-file=/root/.my.cnf -Bse "RESET BINARY LOGS AND GTIDS"
          # Configure DR channel
          mysql --defaults-file=/root/.my.cnf -Bse "SET SQL_LOG_BIN=0;CHANGE REPLICATION SOURCE TO SOURCE_USER='replica', SOURCE_PASSWORD='${mysql_replica_password}' FOR CHANNEL 'group_replication_recovery';"
          mysql --defaults-file=/root/.my.cnf -Bse "START GROUP_REPLICATION;"
      fi
