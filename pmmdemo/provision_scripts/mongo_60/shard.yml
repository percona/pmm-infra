#cloud-config
fqdn: ${fqdn}
hostname: ${name}
manage_etc_hosts: true
prefer_fqdn_over_hostname: true
preserve_hostname: false
package_upgrade: true
package_update: true

packages:
  - bind-utils
  - curl
  - jq

bootcmd:
  - while [[ ! -b $(readlink -f /dev/nvme1n1) ]]; do echo "waiting for the disk..."; sleep 5; done
  - mkfs.xfs -L data /dev/nvme1n1
  - mkdir -p /data

mounts:
  - ["/dev/nvme1n1", "/data", "xfs", "defaults,nofail,noatime", "0", "2"]

runcmd:
  - dnf config-manager --add-repo https://rpm.releases.hashicorp.com/AmazonLinux/hashicorp.repo
  - dnf -y install consul
  - systemctl enable consul && systemctl start consul
  - dnf -y install https://repo.percona.com/yum/percona-release-latest.noarch.rpm
  - percona-release setup -y pmm3-client
  - dnf -y install pmm-client
  - bash /usr/local/bin/waiter.sh readyz
  - pmm-admin config --az="us-east-1f" --region="us-east-1" --metrics-mode=push --force --server-insecure-tls --server-url='https://admin:${pmm_password}@${pmm_server_endpoint}' ${fqdn} generic ${name}
  - dnf -y install https://github.com/ncabatoff/process-exporter/releases/download/v0.8.5/process-exporter_0.8.5_linux_amd64.rpm
  - bash /usr/local/bin/waiter.sh process-exporter
  - pmm-admin add external --group=processes --listen-port=9256 --environment="prod" --service-name="${name}-processes" --cluster="processes-cluster"
  - percona-release setup -y psmdb-60
  - PERCONA_TELEMETRY_DISABLE=1 dnf -y install percona-server-mongodb
  - chown mongod:mongod /data/ /etc/mongo-key
  - chmod 600 /etc/mongo-key
  - systemctl enable mongod
  - systemctl start mongod
  - bash /usr/local/bin/waiter.sh mongodb
  - bash /tmp/mongodb-init-rs.sh
  - bash /usr/local/bin/waiter.sh mongo-rs
  - pmm-admin add mongodb --port 27019 --username=pmm --password='${mongodb_60_pmm_user_password}' --cluster='mdb60-cluster' --replication-set='mongo-60-rs-${shard_number}' --environment='prod' --service-name=${name} --enable-all-collectors

write_files:
  - path: /etc/resolv.conf
    permissions: "0644"
    content: |
      ; generated by #cloud-config
      search ${local_domain} ec2.internal
      options timeout:2 attempts:5
      nameserver 10.0.0.2
  - path: /etc/consul.d/consul.hcl
    permissions: "0644"
    content: |
      bind_addr = "0.0.0.0"
      client_addr = "0.0.0.0"
      data_dir = "/opt/consul"
      enable_local_script_checks = true
      node_name="${name}"
      retry_join = ["pmm-server", "sysbench", "bastion"]
      server = false
  - path: /etc/consul.d/mongod-service.json
    permissions: "0644"
    content: |
      {
        "services": [
          {
            "address": "${fqdn}",
            "id": "mongo-60-rs-${replica_set_name}",
            "name": "mongo-60-rs-${replica_set_name}",
            "port": 27019,
            "tags": ["${name}"],
            "checks": [{
              "args": ["mongosh", "--port", "27019", "--eval", "db.runCommand(\"ping\").ok", "-quiet"],
              "interval": "10s"
            }]
          },
          {
            "address": "${fqdn}",
            "id": "mongo-60-rs-${shard_number}-primary",
            "name": "mongo-60-rs-${shard_number}-primary",
            "tags": ["${name}"],
            "checks": [{
              "args": ["/usr/local/bin/mongo_is_primary.sh"],
              "interval": "10s"
            }]
          }
        ]
      }
  - path: /etc/consul.d/process-exporter-check-http.json
    permissions: "0644"
    content: |
      {
        "service": {
          "address": "${fqdn}",
          "id": "process-exporter",
          "name": "process-exporter",
          "port": 9256,
          "tags": ["${name}"],
          "checks": [
            {
            "HTTP": "http://${fqdn}:9256/metrics",
            "ID": "process-exporter_check_http",
            "Interval": "3s",
            "Method": "GET",
            "Name": "Check for process-exporter using HTTP",
            "Notes": "Check for process-exporter using HTTP. Monitoring of per-process metrics are enabled with this service.",
            "ServiceID": "process-exporter_check_http",
            "Success_before_passing": 3,
            "Timeout": "5s"
            }
          ]
        }
      }
  - path: /usr/local/bin/waiter.sh
    permissions: "0755"
    content: |
      #!/bin/bash
      # Script to do all the waiting
      service="$1"
      if [[ $service == "process-exporter" ]]; then
        # process-exporter
        while true; do
          # Get the status of the process-exporter_check_http check
          status=$(dig @127.0.0.1 -p 8600 ${name}.process-exporter.service.consul SRV | awk '/SRV.*${fqdn}\.$/ {print $1}')

          if [[ $status == "${name}.process-exporter.service.consul." ]]; then
            echo "process-exporter check is passing."
            exit 0
          fi

          # If the check is not passing, wait for a short interval and try again
          echo "process-exporter check is not passing. Will retry in 3 seconds..."
          sleep 3
        done
      elif [[ $service == "mongodb" ]]; then
        # mongodb
        while true; do
          # Get the status of the mongodb check
          status=$(dig @127.0.0.1 -p 8600 ${name}.mongo-60-rs-${replica_set_name}.service.consul SRV | awk '/SRV.*${fqdn}\.$/ {print $1}')
          if [[ $status == "${name}.mongo-60-rs-${replica_set_name}.service.consul." ]]; then
            echo "mongodb check is passing."
            exit 0
          fi
          # If the check is not passing, wait for a short interval and try again
          echo "mongodb check is not passing. Will retry in 3 seconds..."
          sleep 3
        done
      elif [[ $service == "mongo-rs" ]]; then
        # wait for all 3 members of this mongo replica set
        while true; do
          # Get the count of members in this replica set
          cnt=$(dig +short @127.0.0.1 -p 8600 mongo-60-rs-${replica_set_name}.service.consul SRV | wc -l)
          if [[ $cnt -eq 3 ]]; then
            echo "3 shards online"
            exit 0
          fi
          # If the check is not passing, wait for a short interval and try again
          echo "Only $${cnt} shards online, expecting 3. Will retry in 3 seconds..."
          sleep 3
        done
      elif [[ $service == "readyz" ]] ; then
        # PMM readyz
        while true; do
          # Check for DNS :facepalm:
          dnsstatus=$(dig pmm-server.${environment_name}.local A | awk '/A.*10.*$/ {print $1}')

          if [[ $dnsstatus == "pmm-server.${environment_name}.local." ]]; then
            echo "PMMreadyz_check_http DNS check is passing."

            # Get the status of the PMMreadyz_check_http check
            status=$(dig @127.0.0.1 -p 8600 pmmreadyz.service.consul SRV | awk '/SRV.*bastion.${environment_name}.local.$/ {print $1}')
        
            if [[ $status == "pmmreadyz.service.consul." ]]; then
              echo "PMMreadyz_check_http check is passing."
              exit 0  
            fi
          else
            echo "PMMreadyz_check_http DNS check is not passing."
          fi
          # If the check is not passing, wait for a short interval and try again
          echo "PMMreadyz_check_http check is not passing. Will retry in 1 second..."
          sleep 1
        done
      fi

  - path: /usr/local/bin/mongo_is_primary.sh
    permissions: "0755"
    content: |
        #!/bin/bash
        masterstat=$(NO_COLOR=1 /bin/mongosh --port 27019 -u pmm -p ${mongodb_60_pmm_user_password} --quiet --eval 'd=db.isMaster();EJSON.stringify(d.ismaster+"#"+d.primary)')
        primary=$(echo $masterstat | cut -d# -f2 | rev | cut -c2- | rev)
        ismaster=$(echo $masterstat | cut -d# -f1)
        echo "$primary is primary"
        if [[ "$${ismaster:1}" =~ "true" ]]; then
          exit 0
        else
          exit 2
        fi

  - path: /etc/mongosh.conf
    content: |
      enableTelemetry: false

  - path: /etc/mongod.conf
    content: |
      sharding:
        clusterRole: shardsvr

      replication:
        replSetName: ${replica_set_name}

      storage:
        dbPath: /data
        journal:
          enabled: true

      systemLog:
        destination: file
        logAppend: true
        path: /var/log/mongo/mongod.log

      setParameter:
        logLevel: 0        

      processManagement:
        fork: true
        pidFilePath: /var/run/mongod.pid

      net:
        port: 27019
        bindIp: 0.0.0.0

      operationProfiling:
        mode: all
        slowOpThresholdMs: 200
        rateLimit: 100

      security:
        keyFile: /etc/mongo-key

  - path: /etc/mongo-key
    content: |
      ${mongodb_60_keyfile}

  - path: /tmp/init.js
    content: |
      db.getMongo().setReadPref("primaryPreferred")
      rs.initiate({
        _id: "${replica_set_name}",
        members: [
          { _id : 0, host : "mongo-60-rs-${shard_number}-0.${route53_name}:27019", priority: 2 },
          { _id : 1, host : "mongo-60-rs-${shard_number}-1.${route53_name}:27019", priority: 1 },
          { _id : 2, host : "mongo-60-rs-${shard_number}-2.${route53_name}:27019", priority: 1 }
        ]
      })

  - path: /tmp/admin.js
    content: |
      admin = db.getSiblingDB("admin")
      admin.createUser({
        user: "perconaadmin",
        pwd: "${mongodb_60_percona_admin_password}",
        roles: [
            { role: "userAdminAnyDatabase", db: "admin" },
            { role: "clusterAdmin", db: "admin" }
        ]
      })

  - path: /tmp/users.js
    content: |
      db.getSiblingDB("admin").createRole({
          role: "explainRole",
          privileges: [{
            resource: { db: '', collection: '' },
            actions: [
              'collStats',
              'dbStats',
              'indexStats',
              'dbHash',
              'find',
              'listCollections',
              'listIndexes'
            ]
          },
          {
            resource: { db: '', collection: 'system.version' },
            actions: [ 'find' ]
          },
          {
            resource: { db: '', collection: 'system.profile' },
            actions: [ 'collStats', 'dbStats', 'indexStats' ]
          }],
          roles:[]
      });
      db.getSiblingDB("admin").createUser({
        user: "pmm",
        pwd: "${mongodb_60_pmm_user_password}",
        roles: [
            { role: "explainRole", db: "admin" },
            { role: "clusterMonitor", db: "admin" },
            { role: "read", db: "local" }
        ]
      });
      db.getSiblingDB("admin").createUser({
        user: "ycsb",
        pwd: "${mongodb_ycsb_password}",
        roles: [
            { role: "readWrite", db: "ycsb" }
        ]
      });

  - path: /tmp/mongodb-init-rs.sh
    permissions: "0700"
    content: |
      #!/bin/bash

      myhostname=$(hostname -f)
      memberid=$(hostname -f | cut -d. -f1 | cut -d'-' -f5)

      echo "-- MongoDB RS"
      echo "--- $${myhostname}"
      echo "--- This is member id $${memberid}"

      echo "-- Waiting for mongo to start on all 3 members..."
      /usr/local/bin/waiter.sh mongo-rs

      # We pick rs-[01]-0 to be primary. Run the init only on the primary
      if [ "$${memberid}" == "0" ]; then
        echo "-- We are shard 0; run init"
        mongosh --port 27019 /tmp/init.js
      else
        echo "-- We are NOT shard 0; We will wait"
      fi

      # Wait for replicaset to have 3 members
      /usr/local/bin/waiter.sh mongo-rs

      # Print report to cloud log
      echo "-- ReplicaSet Members:"
      mongosh --port 27019 -quiet --eval "var m=db.adminCommand({replSetGetStatus:1}).members; m.forEach(function(a){ print(a.stateStr+':'+a.name); });"

      # Determine/wait for primary
      for (( i=1 ; i<=100 ; i++ )); do
        primary=$(mongosh --port 27019 --eval 'rs.isMaster().primary' -quiet | cut -d: -f1)
        if [ "$${primary:0:5}" == "mongo" ]; then
          echo "-- $${primary} is PRIMARY, we are $${myhostname}"
          sleep 2
          break
        fi
        echo "-- Waiting on a primary, retry $${i}/100"
        sleep 2
      done

      # Is this host PRIMARY? If so, create the admin user, and pmm user
      if [ "$${myhostname}" == "$${primary}" ]; then
        echo "-- We are PRIMARY!"
        mongosh --port 27019 /tmp/admin.js
        sleep 2
        mongosh --port 27019 -u perconaadmin -p '${mongodb_60_percona_admin_password}' /tmp/users.js
      else
        echo "-- We are NOT primary, waiting for auth"
        # Since we are not primary, we need to wait until the primary has replicated
        # the PMM user to us, otherwise pmm add mongo will fail

        for (( i=1 ; i<=100 ; i++ )); do
          # This will fail until auth replicates, so we keep running the ping with auth until it no longer fails
          ret=$(mongosh --port 27019 -quiet --eval 'db.runCommand("ping").ok' -u perconaadmin -p "${mongodb_60_percona_admin_password}" 2>&1 >/dev/null)
          if [ $? -eq 0 ]; then
            echo "-- Auth is enabled"
            break
          fi
          echo "-- Waiting on auth, retry $${i}/100"
          sleep 2
        done
      fi
